{
  "best_metric": 0.08477647602558136,
  "best_model_checkpoint": "./vector_gpt_trainer/checkpoint-220",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 220,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.22727272727272727,
      "grad_norm": 0.7254325151443481,
      "learning_rate": 9.999999999999999e-06,
      "loss": 0.677,
      "step": 10
    },
    {
      "epoch": 0.45454545454545453,
      "grad_norm": 0.6649035215377808,
      "learning_rate": 1.9999999999999998e-05,
      "loss": 0.6175,
      "step": 20
    },
    {
      "epoch": 0.6818181818181818,
      "grad_norm": 0.5999647378921509,
      "learning_rate": 2.9999999999999997e-05,
      "loss": 0.5052,
      "step": 30
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 0.5037648677825928,
      "learning_rate": 3.9999999999999996e-05,
      "loss": 0.3628,
      "step": 40
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.23084594309329987,
      "eval_runtime": 0.096,
      "eval_samples_per_second": 1562.198,
      "eval_steps_per_second": 104.147,
      "step": 44
    },
    {
      "epoch": 1.1363636363636362,
      "grad_norm": 0.3508130609989166,
      "learning_rate": 4.9999999999999996e-05,
      "loss": 0.2296,
      "step": 50
    },
    {
      "epoch": 1.3636363636363638,
      "grad_norm": 0.17671498656272888,
      "learning_rate": 5.9999999999999995e-05,
      "loss": 0.1475,
      "step": 60
    },
    {
      "epoch": 1.5909090909090908,
      "grad_norm": 0.09170703589916229,
      "learning_rate": 7e-05,
      "loss": 0.1136,
      "step": 70
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 0.08085508644580841,
      "learning_rate": 7.999999999999999e-05,
      "loss": 0.1025,
      "step": 80
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.09287204593420029,
      "eval_runtime": 0.0954,
      "eval_samples_per_second": 1571.56,
      "eval_steps_per_second": 104.771,
      "step": 88
    },
    {
      "epoch": 2.0454545454545454,
      "grad_norm": 0.055493660271167755,
      "learning_rate": 8.999999999999999e-05,
      "loss": 0.0974,
      "step": 90
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 0.04260184243321419,
      "learning_rate": 9.999999999999999e-05,
      "loss": 0.0946,
      "step": 100
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.042525190860033035,
      "learning_rate": 0.00010999999999999998,
      "loss": 0.0929,
      "step": 110
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 0.04021969437599182,
      "learning_rate": 0.00011999999999999999,
      "loss": 0.0918,
      "step": 120
    },
    {
      "epoch": 2.9545454545454546,
      "grad_norm": 0.043145351111888885,
      "learning_rate": 0.00013,
      "loss": 0.0909,
      "step": 130
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.08712591975927353,
      "eval_runtime": 0.0942,
      "eval_samples_per_second": 1592.326,
      "eval_steps_per_second": 106.155,
      "step": 132
    },
    {
      "epoch": 3.1818181818181817,
      "grad_norm": 0.035542797297239304,
      "learning_rate": 0.00014,
      "loss": 0.09,
      "step": 140
    },
    {
      "epoch": 3.409090909090909,
      "grad_norm": 0.03961664065718651,
      "learning_rate": 0.00015,
      "loss": 0.0897,
      "step": 150
    },
    {
      "epoch": 3.6363636363636362,
      "grad_norm": 0.04452972114086151,
      "learning_rate": 0.00015999999999999999,
      "loss": 0.0891,
      "step": 160
    },
    {
      "epoch": 3.8636363636363638,
      "grad_norm": 0.041149117052555084,
      "learning_rate": 0.00016999999999999999,
      "loss": 0.0888,
      "step": 170
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.08544512093067169,
      "eval_runtime": 0.0922,
      "eval_samples_per_second": 1626.998,
      "eval_steps_per_second": 108.467,
      "step": 176
    },
    {
      "epoch": 4.090909090909091,
      "grad_norm": 0.046458326280117035,
      "learning_rate": 0.00017999999999999998,
      "loss": 0.0886,
      "step": 180
    },
    {
      "epoch": 4.318181818181818,
      "grad_norm": 0.050199244171381,
      "learning_rate": 0.00018999999999999998,
      "loss": 0.0882,
      "step": 190
    },
    {
      "epoch": 4.545454545454545,
      "grad_norm": 0.04678478464484215,
      "learning_rate": 0.00019999999999999998,
      "loss": 0.088,
      "step": 200
    },
    {
      "epoch": 4.7727272727272725,
      "grad_norm": 0.04802260175347328,
      "learning_rate": 0.00020999999999999998,
      "loss": 0.0877,
      "step": 210
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.0513000525534153,
      "learning_rate": 0.00021999999999999995,
      "loss": 0.0877,
      "step": 220
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.08477647602558136,
      "eval_runtime": 0.0871,
      "eval_samples_per_second": 1722.045,
      "eval_steps_per_second": 114.803,
      "step": 220
    }
  ],
  "logging_steps": 10,
  "max_steps": 220,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
